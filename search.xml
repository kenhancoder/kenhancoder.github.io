<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>使用Tornado中的WebSocket</title>
      <link href="/2017/08/13/use-tornado-websocket/"/>
      <url>/2017/08/13/use-tornado-websocket/</url>
      <content type="html"><![CDATA[<p>Tornado已经实现了对WebSocket的封装。</p><p>以下是源码提供Demo的部分代码。Tornado的github地址：<a href="https://github.com/tornadoweb/tornado" target="_blank" rel="noopener">https://github.com/tornadoweb/tornado</a></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChatSocketHandler</span><span class="params">(tornado.websocket.WebSocketHandler)</span>:</span></span><br><span class="line">    waiters = set()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self)</span>:</span></span><br><span class="line">        ChatSocketHandler.waiters.add(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_close</span><span class="params">(self)</span>:</span></span><br><span class="line">        ChatSocketHandler.waiters.remove(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_message</span><span class="params">(self, message)</span>:</span></span><br><span class="line">        logging.info(<span class="string">"got message %r"</span>, message)</span><br><span class="line">        self.write_message(<span class="string">u"You said: "</span> + message)</span><br></pre></td></tr></table></figure><p>在此ChatSocketHandler中override了open、on_close、on_message方法。</p><blockquote><ul><li>open: 在此方法体内，可以进行开启连接后的操作</li><li>on_close: 在此方法体内，可以进行关闭连接后的操作</li><li>on_message: 在此方法体内，可以对传入的消息进行操作</li><li>使用write_message方法向已连接客户端发送消息</li></ul></blockquote><p>如果仅仅使用以上的方法，在实际开发中将会遇到跨域的问题。这时需要override下WebSocketHandler中的check_origin</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_origin</span><span class="params">(self, origin)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Tornado </tag>
            
            <tag> WebSocket </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>对Tornado异步操作Sqlalchemy方法的选定</title>
      <link href="/2017/08/13/tornado-sqlalchemy-async/"/>
      <url>/2017/08/13/tornado-sqlalchemy-async/</url>
      <content type="html"><![CDATA[<h3 id="使用原因"><a href="#使用原因" class="headerlink" title="使用原因"></a>使用原因</h3><p>在一个实时通讯的项目中，由于需要使用Websocket这一协议，便在Python框架中选定了Tornado，也同时使用了Sqlalchemy这一ORM框架。<br>大家都知道Tornado有异步非阻塞特性，但Sqlalchemy是同步操作，这会大大影响性能，会影响的用户体验。<br>为了能解决这一问题，我便在网上搜寻资料，发现有使用Celery的，有使用run_on_executor装饰器的，甚至自己封装异步Sqlalchemy的等等方法。<br>由于缺少实践，我觉定对Celery、run_on_executor进行尝试</p><h3 id="Celery"><a href="#Celery" class="headerlink" title="Celery"></a>Celery</h3><p>以下是官方文档的介绍：</p><blockquote><p>Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。<br>它是一个专注于实时处理的任务队列，同时也支持任务调度。<br>Celery 有广泛、多样的用户与贡献者社区，你可以通过 IRC 或是 邮件列表 加入我们。<br>Celery 是开源的，使用 BSD 许可证 授权。</p></blockquote><p>官网地址：<a href="http://docs.jinkan.org/docs/celery/" target="_blank" rel="noopener">http://docs.jinkan.org/docs/celery/</a></p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><blockquote><p>服务器：Ubuntu 12.04.5 LTS (GNU/Linux 3.2.0-67-generic x86_64)</p></blockquote><ul><li><p>安装RabbitMQ</p><ul><li>安装RabbitMQ Server<ul><li><code>sudo apt-get install rabbitmq-server</code></li><li><blockquote><p>RabbitMQ提供了一些简单实用的命令用于管理服务器运行状态：<br>查看服务器运行状态: enable rabbitmq_management<br>启动服务器:rabbitmq-server start<br>停止服务器:rabbitmq-server stop<br>查看服务器中所有的消息队列信息 :rabbitmqctl list_queues<br>查看服务器种所有的路由信息: rabbitmqctl list_exchanges<br>查看服务器种所有的路由与消息队列绑定信息 :rabbitmq list_bindings</p></blockquote></li></ul></li><li><p>启用WEB管理台</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/usr/lib/rabbitmq/bin</span><br><span class="line">sudo ./rabbitmq-plugins enable rabbitmq_management</span><br></pre></td></tr></table></figure></li><li><p>添加远程管理账户<br>  将下面配置写入/etc/rabbitmq/rabbitmq.conf.d/rabbitmq.config文件中</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;rabbit, [&#123;tcp_listeners, [5672]&#125;, &#123;loopback_users, [&quot;ken&quot;]&#125;]&#125;</span><br><span class="line">].</span><br></pre></td></tr></table></figure><p>  执行命令</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /usr/lib/rabbitmq/bin/</span><br><span class="line">sudo rabbitmqctl add_user ken 123456</span><br><span class="line">sudo rabbitmqctl set_user_tags ken administrator</span><br><span class="line">sudo rabbitmqctl set_permissions -p / ken &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>安装Celery<br>  Celery详情查看<a href="http://docs.jinkan.org/docs/celery/getting-started/first-steps-with-celery.html" target="_blank" rel="noopener">官方文档</a></p><ul><li>使用pip安装<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install Celery</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="Celery方法示例"><a href="#Celery方法示例" class="headerlink" title="Celery方法示例"></a>Celery方法示例</h3><ul><li>新建一个task.py</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from celery import Celery</span><br><span class="line"></span><br><span class="line">celery = Celery(&apos;tasks&apos;, broker=&apos;amqp://&apos;)</span><br><span class="line">celery.conf.CELERY_RESULT_BACKEND = os.environ.get(&apos;CELERY_RESULT_BACKEND&apos;, &apos;amqp&apos;)</span><br><span class="line"></span><br><span class="line">@celery.task(name=&apos;task.db_operation&apos;)</span><br><span class="line">def db_operation(id):</span><br><span class="line">    # 耗时的数据库操作</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure><ul><li>使用worker参数执行我们的程序的task</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">celery -A tasks worker --loglevel=info</span><br></pre></td></tr></table></figure><ul><li>新建一个handler.py</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import tcelery</span><br><span class="line">tcelery.setup_nonblocking_producer()</span><br><span class="line"></span><br><span class="line">from tasks import db_operation</span><br><span class="line"></span><br><span class="line">calss Resource(RequestHandler):</span><br><span class="line">    @asynchronous</span><br><span class="line">    def get():</span><br><span class="line">        # 参数通过args传递,回调通过callback指定</span><br><span class="line">        db_operation.apply_async(args=[id], callback=self.on_success)</span><br><span class="line">    def on_success(self, response):</span><br><span class="line">        # 获取返回的结果</span><br><span class="line">        resource = response.result</span><br><span class="line">        self.write(resource)</span><br><span class="line">        self.finish()</span><br></pre></td></tr></table></figure><p>此时，Resource的Get请求已经变成异步非阻塞了。</p><h3 id="run-on-executor方法示例"><a href="#run-on-executor方法示例" class="headerlink" title="run_on_executor方法示例"></a>run_on_executor方法示例</h3><ul><li>新建一个handler.py</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from concurrent.futures import ThreadPoolExecutor</span><br><span class="line">from tornado.concurrent import run_on_executor</span><br><span class="line"></span><br><span class="line">class ChatHandler(web.RequestHandler):</span><br><span class="line">    executor = ThreadPoolExecutor(4)</span><br><span class="line"></span><br><span class="line">    @web.asynchronous</span><br><span class="line">    @gen.coroutine</span><br><span class="line">    def get(self):</span><br><span class="line">        resource = yield self.get_db_operation()</span><br><span class="line">        self.write(resource)</span><br><span class="line">        self.finish()</span><br><span class="line"></span><br><span class="line">    @web.asynchronous</span><br><span class="line">    @gen.coroutine</span><br><span class="line">    def post(self):</span><br><span class="line">        yield self.post_db_operation()</span><br><span class="line">        self.write(&apos;success&apos;)</span><br><span class="line">        self.finish()</span><br><span class="line"></span><br><span class="line">    @run_on_executor</span><br><span class="line">    def get_db_operation(self):</span><br><span class="line">        return resource</span><br><span class="line"></span><br><span class="line">    @run_on_executor</span><br><span class="line">    def post_db_operation(self):</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这一整套走下来，个人觉得使用Celery部署麻烦，而且一旦大量使用Celery，极有可能导致队列长度过长，影响处理效率。最后我选择使用了run_on_executor方法。</p>]]></content>
      
      
        <tags>
            
            <tag> Tornado </tag>
            
            <tag> Sqlalchemy </tag>
            
            <tag> Celery </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis与Memcached的比较</title>
      <link href="/2017/08/13/redis-memcached-compare/"/>
      <url>/2017/08/13/redis-memcached-compare/</url>
      <content type="html"><![CDATA[<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><ul><li><p>数据模型</p><blockquote><p>Redis的外围由一个键、值映射的字典构成。<br>与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于字符串，还支持如下抽象数据类型：<br>字符串列表<br>无序不重复的字符串集合<br>有序不重复的字符串集合<br>键、值都为字符串的哈希表<br>值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。    </p></blockquote></li><li><p>持久化</p><blockquote><p>Redis通常将全部的数据存储在内存中。2.4版本后可配置为使用虚拟内存，一部分数据集存储在硬盘上，但这个特性废弃了。<br>目前通过两种方式实现持久化：<br>使用快照，一种半持久耐用模式。不时的将数据集以异步方式从内存以RDB格式写入硬盘。<br>1.1版本开始使用更安全的AOF格式替代，一种只能追加的日志类型。将数据集修改操作记录起来。Redis能够在后台对只可追加的记录作修改来避免无限增长的日志。    </p></blockquote></li><li><p>同步</p><blockquote><p>Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。从盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。    </p></blockquote></li><li><p>性能</p><blockquote><p>当数据依赖不再需要，Redis这种基于内存的性质，与在执行一个事务时将每个变化都写入硬盘的数据库系统相比就显得执行效率非常高。写与读操作速度没有明显差别。    </p></blockquote></li></ul><h3 id="Memcached"><a href="#Memcached" class="headerlink" title="Memcached"></a>Memcached</h3><p>Memcache是一个高性能的分布式的内存对象缓存系统，通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。简单的说就是将数据调用到内存中，然后从内存中读取，从而大大提高读取速度。    </p><blockquote><p>######特征：</p><ul><li>协议简单<br> 它是基于文本行的协议，直接通过telnet在memcached服务器上可进行存取数据操作</li><li>基于libevent事件处理<br>  Libevent是一套利用C开发的程序库，它将BSD系统的kqueue,Linux系统的epoll等事件处理功能封装成一个接口，与传统的select相比，提高了性能。</li><li>内置的内存管理方式<br>  所有数据都保存在内存中，存取数据比硬盘快，当内存满后，通过LRU算法自动删除不使用的缓存，但没有考虑数据的容灾问题，重启服务，所有数据会丢失。</li><li>分布式<br> 各个memcached服务器之间互不通信，各自独立存取数据，不共享任何信息。服务器并不具有分布式功能，分布式部署取决于memcache客户端。</li></ul></blockquote><h3 id="Redis与Memcached的不同"><a href="#Redis与Memcached的不同" class="headerlink" title="Redis与Memcached的不同"></a>Redis与Memcached的不同</h3><ul><li>Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份。</li><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis在很多方面具备数据库的特征，或者说就是一个数据库系统，而Memcached只是简单的K/V缓存。</li><li>memcache只能当做缓存，cache。redis的内容是可以落地的，类似数据库，然后redis也可以作为缓存，并且可以设置master-slave。</li></ul>]]></content>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Memcached </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python中使用Redis遭遇打开文件数过多</title>
      <link href="/2017/08/13/redis-1/"/>
      <url>/2017/08/13/redis-1/</url>
      <content type="html"><![CDATA[<p>今天服务突然爆出好多异常日志：<br><code>ConnectionError: Error 24 connecting to 127.0.0.1:6379. Too many open files.</code></p><p>通过命令<code>cat /proc/(redis-sever_PID)/limits</code>获得<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Max open files  4016  4016  files</span><br></pre></td></tr></table></figure></p><p>第一反应是觉得可能4016过小，所以需要对其升值。</p><p>编辑/etc/sysctl.conf 添加如下内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fs.file-max = 65535</span><br></pre></td></tr></table></figure></p><p>运行<code>sysctl -p</code></p><p>再编辑 /etc/security/limits.conf:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root soft nofile 65536</span><br><span class="line">root hard nofile 65536</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br></pre></td></tr></table></figure></p><p>使用命令<code>ulimit -n 65535</code>，将最大文件数提高至65535，这种修改只是在当前shell中生效，想要真正对Redis中<strong>Max open files</strong>进行修改，就需要在当前shell中进行重启redis，然后服务就恢复了正常。<strong>这种方法其实是治标不治本的</strong></p><p>在临时解决异常问题后，需要思考为什么会有这么多未释放的连接。</p><p>经过分析，在创建Redis连接时，都会创建一个ConnectionPool。这导致，每获取一个StrictRedis时，都会创建一个新的ConnectionPool，这才是导致文件数过多的原因。</p><p>解决方案：</p><p>先创建创建一个ConnectionPool<br><code>pool = redis.ConnectionPool(host=&#39;localhost&#39;, port=6379, db=0)</code></p><p>然后创建一个Redis<br><code>r = redis.Redis(connection_pool=pool)</code></p>]]></content>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python基础复习-Set(一)</title>
      <link href="/2017/08/13/python-set-1/"/>
      <url>/2017/08/13/python-set-1/</url>
      <content type="html"><![CDATA[<h3 id="Set（-集合）"><a href="#Set（-集合）" class="headerlink" title="Set（ 集合）"></a>Set（ 集合）</h3><p>花大括号或 set() 函数可以用于创建集合。注意： 若要创建一个空集必须使用set()，而不能用 {}<br>set() -&gt; new empty set object<br>set(iterable) -&gt; new set object<br>集合中的元素不会重复且没有顺序。<br>集合的基本用途包括成员测试和消除重复条目。<br>集合对象还支持并集（union）、 交集（intersection）、 差（difference）和对称差（symmetric_difference）等数学运算。<br>查询时用到了Hash，时间在O(1)级别<br>set是无序unique值的集合，常用来去重，检验membership等。<br>set类似一个词典，但只有键key，没有值value，好多操作也类似，但不支持索引，切片等操作。</p><h3 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h3><ol><li>无序</li><li>元素不重复</li><li>成员检测时效率快</li></ol><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><blockquote><p>set.add(x)<br>添加一个元素x到集合中。如果元素已存在, 该操作是无效的。因为集合里的元素是不重复的。<br><br><br>set.clear()<br>清空集合内的元素。集合变为空集<br><br><br>set.copy()<br>返回集合的一个浅拷贝。<br><br><br>set.difference(…)<br>返回一个新集合，新集合为两个或者多个集合的差集。例 a.difference(b,c)，返回元素在a中，但不在b、c中<br><br><br>set.difference_update(…)<br>将别的集合中的元素从本集合中删除。例  a.difference_update(b, c), 将b、c中的元素从a中删除<br><br><br>set.discard(x)<br>删除集合中的一个元素x。如果x不是集合中的成员，该操作是无效的。<br><br><br>set.intersection(…)<br>返回一个新集合，新集合为两个或者多个集合的交集。<br><br><br>set.intersection_update(…)<br>将集合中的元素更新为与其它集合的交集。例 a.intersection_update(b,c)，a中的元素为a、b、c的交集<br><br><br>set.isdisjoint(s)<br>如果两个集合的交集为空集，则返回True，反之为False<br><br><br>set.issubset(s)<br>如果集合s包含本集合set，则返回True，反之为False<br><br><br>set.issuperset(s)<br>如果本集合set包含集合s，则返回True，反之为False<br><br><br>set.pop()<br>删除并且返回集合set中的一个不确定的元素, 如果集合set为空，将会抛出异常KeyError<br><br><br>set.remove(e)<br>删除集合set中的一个元素e，如果元素e不是集合set的成员，将会抛出异常KeyError<br><br><br>set.symmetric_difference(s)<br>返回一个新的对称差集合，即该集合包含集合set和集合s中不重复的元素，同并集减交集<br><br><br>set.symmetric_difference_update(s)<br>将集合set更新为集合set和集合s的对称差集合<br><br><br>set.union(…)<br>返回一个新的集合，该集合为两个或者多个集合的并集。<br><br><br>set.update(…)<br>将集合set更新为多个集合的并集    </p></blockquote><h3 id="集合操作符号"><a href="#集合操作符号" class="headerlink" title="集合操作符号"></a>集合操作符号</h3><blockquote><p>差集：-<br>交集：&amp;<br>并集：|<br>等于，不等于：==，！=<br>属于，不属于：in, not in    </p></blockquote>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Set </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python的logging模块的复习和使用</title>
      <link href="/2017/08/13/python-logging/"/>
      <url>/2017/08/13/python-logging/</url>
      <content type="html"><![CDATA[<p>在之前的多个项目中都有用到过logging模块，虽然用过，但没有研究过，只是在每个代码文件中使用<code>logger=logging.getLogger(__name__)</code>这样简单粗暴的方法。</p><p>在这次的使用经历中，觉得logging模块真的很不错。</p><h3 id="logging"><a href="#logging" class="headerlink" title="logging"></a>logging</h3><p>使用logging前，必须先要了解它的重要概念。</p><ul><li><strong>Logging Levels</strong></li><li><strong>Logger Objects</strong></li><li><strong>Handler Objects</strong></li><li><strong>Formatter Objects</strong></li><li><strong>Filter Objects</strong></li></ul><h3 id="Level"><a href="#Level" class="headerlink" title="Level"></a>Level</h3><p>Level 级别。只有在日志消息的级别大于logger和handler设定的级别，才会显示。</p><table><thead><tr><th>级别</th><th>何时使用</th></tr></thead><tbody><tr><td>NOTSET</td><td>不设置级别</td><td>0</td></tr><tr><td>DEBUG</td><td>详细信息，调试时</td><td>10</td></tr><tr><td>INFO</td><td>证明事情按预期工作。</td><td>20</td></tr><tr><td>WARNING</td><td>表明发生了一些意外，或者不久的将来会发生问题（如‘磁盘满了’）。软件还是在正常工作。</td><td>30</td></tr><tr><td>ERROR</td><td>由于更严重的问题，软件已不能执行一些功能了。</td><td>40</td></tr><tr><td>CRITICAL</td><td>严重错误，表明软件已不能继续运行了。</td><td>50</td></tr></tbody></table><h3 id="Logger"><a href="#Logger" class="headerlink" title="Logger"></a>Logger</h3><p>Logger 记录器，暴露了应用程序代码能直接使用的接口。</p><p>Logger是一个树形层级结构，在使用接口debug，info，warn，error，critical之前必须创建Logger实例，即创建一个记录器，如果没有显式的进行创建，则默认创建一个root logger，并应用默认的日志级别(WARN)，处理器Handler(StreamHandler，即将日志信息打印输出在标准输出上)，和格式化器Formatter(默认的格式即为第一个简单使用程序中输出的格式)。</p><p>创建方法: <code>logger = logging.getLogger(name=None)</code>。如果不指定name则返回root logger对象。</p><p>常用方法如下：</p><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>addHandler(self, hdlr)</td><td>Add the specified handler to this logger.</td></tr><tr><td>removeHandler(self, hdlr)</td><td>Remove the specified handler from this logger.</td></tr><tr><td>setLevel(self, level)</td><td>Set the logging level of this logger.</td></tr></tbody></table><h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><p>Handler 处理器，将（记录器产生的）日志记录发送至合适的目的地。</p><p>比较常用的有三个，StreamHandler，FileHandler，NullHandler，详情可以访问<a href="!https://docs.python.org/2.7/library/logging.handlers.html#module-logging.handlers">地址</a></p><p>Handler处理器类型如下：</p><ul><li>StreamHandler</li><li>FileHandler</li><li>NullHandler</li><li>WatchedFileHandler</li><li>RotatingFileHandler</li><li>TimedRotatingFileHandler</li><li>SocketHandler</li><li>DatagramHandler</li><li>SysLogHandler</li><li>NTEventLogHandler</li><li>SMTPHandler</li><li>MemoryHandler</li><li>HTTPHandler</li></ul><h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><p>过滤器，提供了更好的粒度控制，它可以决定输出哪些日志记录。</p><p>使用Formatter对象设置日志信息最后的规则、结构和内容，默认的时间格式为%Y-%m-%d %H:%M:%S。</p><p>创建方法: <code>formatter = logging.Formatter(fmt=None, datefmt=None)</code></p><blockquote><p>其中，fmt是消息的格式化字符串，datefmt是日期字符串。如果不指明fmt，将使用’%(message)s’。如果不指明datefmt，将使用ISO8601日期格式。</p></blockquote><h3 id="Formatter"><a href="#Formatter" class="headerlink" title="Formatter"></a>Formatter</h3><p>格式化器，指明了最终输出中日志记录的布局。</p><p>Handlers和Loggers可以使用Filters来完成比级别更复杂的过滤。Filter基类只允许特定Logger层次以下的事件。例如用‘A.B’初始化的Filter允许Logger ‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’等记录的事件，logger‘A.BB’, ‘B.A.B’ 等就不行。 如果用空字符串来初始化，所有的事件都接受。</p><table><thead><tr><th>格式</th><th>描述</th></tr></thead><tbody><tr><td>%(levelno)s</td><td>打印日志级别的数值</td></tr><tr><td>%(levelname)s</td><td>打印日志级别名称</td></tr><tr><td>%(pathname)s</td><td>打印当前执行程序的路径</td></tr><tr><td>%(filename)s</td><td>打印当前执行程序名称</td></tr><tr><td>%(funcName)s</td><td>打印日志的当前函数</td></tr><tr><td>%(lineno)d</td><td>打印日志的当前行号</td></tr><tr><td>%(asctime)s</td><td>打印日志的时间</td></tr><tr><td>%(thread)d</td><td>打印线程id</td></tr><tr><td>%(threadName)s</td><td>打印线程名称</td></tr><tr><td>%(process)d</td><td>打印进程ID</td></tr><tr><td>%(message)s</td><td>打印日志信息</td></tr></tbody></table><h3 id="使用过程"><a href="#使用过程" class="headerlink" title="使用过程"></a>使用过程</h3><p>在项目启动中导入logging模块，然后进行配置，logging标准模块支持三种配置方式: dictConfig，fileConfig，listen。其中，dictConfig是通过一个字典进行配置Logger，Handler，Filter，Formatter；fileConfig则是通过一个文件进行配置；而listen则监听一个网络端口，通过接收网络数据来进行配置。当然，除了以上集体化配置外，也可以直接调用Logger，Handler等对象中的方法在代码中来显式配置。</p><p>basicConfig关键字参数</p><table><thead><tr><th>关键字</th><th>描述</th></tr></thead><tbody><tr><td>filename</td><td>创建一个FileHandler，使用指定的文件名，而不是使用StreamHandler。</td></tr><tr><td>filemode</td><td>如果指明了文件名，指明打开文件的模式（如果没有指明filemode，默认为’a’）。</td></tr><tr><td>format</td><td>handler使用指明的格式化字符串。</td></tr><tr><td>datefmt</td><td>使用指明的日期／时间格式。</td></tr><tr><td>level</td><td>指明根logger的级别。</td></tr><tr><td>stream</td><td>使用指明的流来初始化StreamHandler。该参数与’filename’不兼容，如果两个都有，’stream’被忽略。</td></tr></tbody></table><p>例子：<br>logging.yaml<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">logging:</span><br><span class="line">    version: 1</span><br><span class="line">    formatters:</span><br><span class="line">      brief:</span><br><span class="line">        format: &apos;%(message)s&apos;</span><br><span class="line">      default:</span><br><span class="line">        format: &apos;%(asctime)s %(levelname)-8s %(name)-15s %(message)s&apos;</span><br><span class="line">        datefmt: &apos;%Y-%m-%d %H:%M:%S&apos;</span><br><span class="line">      fluent_fmt:</span><br><span class="line">        &apos;()&apos;: fluent.handler.FluentRecordFormatter</span><br><span class="line">        format:</span><br><span class="line">          loglevel: &apos;%(levelname)s&apos;</span><br><span class="line">          hostname: &apos;%(hostname)s&apos;</span><br><span class="line">          where: &apos;%(module)s.%(funcName)s&apos;</span><br><span class="line">          stack_trace: &apos;%(exc_text)s&apos;</span><br><span class="line">    handlers:</span><br><span class="line">        console:</span><br><span class="line">            class : logging.StreamHandler</span><br><span class="line">            level: DEBUG</span><br><span class="line">            formatter: default</span><br><span class="line">            stream: ext://sys.stdout</span><br><span class="line">        fluent_dev:</span><br><span class="line">            class: fluent.handler.FluentHandler</span><br><span class="line">            host: 127.0.0.1</span><br><span class="line">            port: 24224</span><br><span class="line">            tag: test.dev</span><br><span class="line">            formatter: fluent_fmt</span><br><span class="line">            level: DEBUG</span><br><span class="line">        fluent_prod:</span><br><span class="line">            class: fluent.handler.FluentHandler</span><br><span class="line">            host: 127.0.0.1</span><br><span class="line">            port: 24224</span><br><span class="line">            tag: test.prod</span><br><span class="line">            formatter: fluent_fmt</span><br><span class="line">            level: DEBUG</span><br><span class="line">        null:</span><br><span class="line">            class: logging.NullHandler</span><br><span class="line"></span><br><span class="line">    loggers:</span><br><span class="line">        amqp:</span><br><span class="line">            handlers: [null]</span><br><span class="line">            propagate: False</span><br><span class="line">        conf:</span><br><span class="line">            handlers: [null]</span><br><span class="line">            propagate: False</span><br><span class="line">        dev:</span><br><span class="line">            handlers: [console, fluent_dev]</span><br><span class="line">            level: DEBUG</span><br><span class="line">            propagate: False</span><br><span class="line">        prod:</span><br><span class="line">            handlers: [console, fluent_prod]</span><br><span class="line">            level: DEBUG</span><br><span class="line">            propagate: False</span><br><span class="line">        &apos;&apos;: # root logger</span><br><span class="line">            handlers: [console]</span><br><span class="line">            level: DEBUG</span><br><span class="line">            propagate: False</span><br></pre></td></tr></table></figure></p><p>导入配置方法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import yaml</span><br><span class="line">import logging</span><br><span class="line">import logging.config</span><br><span class="line"></span><br><span class="line">with open(&apos;logging.yaml&apos;) as fd:</span><br><span class="line">    conf = yaml.load(fd)</span><br><span class="line"></span><br><span class="line">logging.config.dictConfig(conf[&apos;logging&apos;])</span><br></pre></td></tr></table></figure></p><p>获取logger<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">logger = logging.getLogger(loggername)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logging </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python基础复习-List(一)</title>
      <link href="/2017/08/13/python-list-1/"/>
      <url>/2017/08/13/python-list-1/</url>
      <content type="html"><![CDATA[<h3 id="List（列表）"><a href="#List（列表）" class="headerlink" title="List（列表）"></a>List（列表）</h3><p>在Python中，用方括号表示一个List，[ ]<br>List是Python中最主要的内置数据类型之一。<br>List中的每个元素都分配一个数字 - 它的位置，或索引，第一个索引是0，第二个索引是1，依此类推。<br>List有序的包含对象，且用户可以自由的增加和删除List里的对象。    </p><h3 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h3><ol><li>可变</li><li>可包含不同类型的元素</li></ol><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><blockquote><p>list.append(x)<br>添加一个元素到列表的末尾。相当于a[len(a):] = [x]。<br><br><br>list.extend(L)<br>将给定列表L中的所有元素附加到原列表a的末尾。相当于a[len(a):] = L。亦同 a + L。<br><br><br>list.insert(i, x)<br>在给定位置插入一个元素。第一个参数是准备插入到其前面的那个元素的索引，所以 a.insert(0, x) 在列表的最前面插入，a.insert(len(a), x) 相当于 a.append(x)。<br><br><br>list.remove(x)<br>删除列表中第一个值为 x 的元素。如果没有这样的元素将会报错。 del<br><br><br>list.pop([i])<br>删除列表中给定位置的元素并返回它。如果未指定索引，a.pop() 删除并返回列表中的最后一个元素。<br><br><br>list.clear()<br>删除列表中所有的元素。相当于del a[:]。<br><br><br>list.index(x)<br>返回列表中第一个值为 x 的元素的索引。如果没有这样的元素将会报错。<br><br><br>list.count(x)<br>返回列表中 x 出现的次数。<br><br><br>list.sort(cmp=None, key=None, reverse=False)<br>原地排序列表中的元素。<br>cmp参数可以允许你提供一个比较函数，根据提供的比较函数来进行排序。改参数在Python3中已经取消。<br>key参数和cmp参数类似，可以提供一个函数，这个函数为每个元素生成一个键，然后根据元素的键来排序。<br>reverse参数是一个Boolean类型的参数，当设置为True时，表示反向排序<br><br><br>list.reverse()<br>反转列表中的元素。相当于[::-1]<br><br><br>list.copy()<br>返回列表的一个浅拷贝。等同于a[:]。<br><br><br>注：append, extend, insert, remove, sort, reverse之类的方法只修改列表而没有返回值打印出来, 它们其实返回了默认值None</p></blockquote><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><blockquote><p>切片操作符在Python中的原型是<br>[start:stop:step]<br>即：[开始索引:结束索引:步长值]<br>开始索引：同其它语言一样，从0开始。序列从左向右方向中，第一个值的索引为0,最后一个为-1<br>结束索引：切片操作符将取到该索引为止，不包含该索引的值。<br>步长值：默认是一个接着一个切取，如果为2,则表示进行隔一取一操作。步长值为正时表示从左向右取，如果为负，则表示从右向左取。步长值不能为0<br><br><br>li = [1,2,3,4,5,6,7]<br><br><br>print li[1:]<br>输出[2,3,4,5,6,7]，省略终止索引，表示取起始索引之后的所有值，等效于li[1:len(li)]<br><br><br>print li[:3]<br>输出[1,2,3]，省略起始索引，表示从0开始取，等效于li[0:3]<br><br><br>print li[:]<br>输出[1,2,3,4,5,6,7]，省略起始索引、终止索引、步长值表示取全部，等效于li[0:len(li):1]<br><br><br>print li[::]<br>输出[1,2,3,4,5,6,7]，省略起始索引、终止索引、步长值表示取全部，等效于li[0:len(li):1]<br><br><br>print li[::-1]<br>输出[7,6,5,4,3,2,1]，省略起始索引、终止索引，步长值为-1，表示反向获取     </p></blockquote><h4 id="和"><a href="#和" class="headerlink" title="+和*"></a>+和*</h4><blockquote><p>两个list可以使用数学运算符+，表示将两个list连接成一个大的list<br>list可以与一个整数使用运算符<em>，表示将list重复n次，形成一个大的list（n是</em>的整数）</p></blockquote>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> List </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python基础复习-GIL(一)</title>
      <link href="/2017/08/13/python-gil-1/"/>
      <url>/2017/08/13/python-gil-1/</url>
      <content type="html"><![CDATA[<h3 id="GIL"><a href="#GIL" class="headerlink" title="GIL"></a>GIL</h3><blockquote><p>GIL，即全局解释器锁（Global Interpreter Lock），是计算机程序设计语言解释器用于同步线程的工具，使得任何时刻仅有一个线程在执行。</p></blockquote><h3 id="Python的GIL"><a href="#Python的GIL" class="headerlink" title="Python的GIL"></a>Python的GIL</h3><blockquote><p>CPython的线程是操作系统的原生线程。在Linux上为pthread，在Windows上为Win thread，完全由操作系统调度线程的执行。一个python解释器进程内有一条主线程，以及多条用户程序的执行线程。即使在多核CPU平台上，由于GIL的存在，所以禁止多线程的并行执行。</p></blockquote><blockquote><p>Python解释器进程内的多线程是合作多任务方式执行。当一个线程遇到I/O任务时，将释放GIL。计算密集型（CPU-bound）的线程在执行大约100次解释器的计步（ticks）时，将释放GIL。计步（ticks）可粗略看作Python虚拟机的指令。计步实际上与时间片长度无关。可以通过sys.setcheckinterval()设置计步长度。</p></blockquote><blockquote><p>在单核CPU上，数百次的间隔检查才会导致一次线程切换。在多核CPU上，存在严重的线程颠簸（thrashing）。</p></blockquote><blockquote><p>Python 3.2开始使用新的GIL。在新的GIL实现中，用一个固定的超时时间来指示当前的线程放弃全局锁。在当前线程保持这个锁，且其他线程请求这个锁的时候，当前线程就会在5ms后被强制释放掉这个锁。</p></blockquote><blockquote><p>可以创建独立的进程来实现并行化。Python 2.6引进了multiprocessing这个多进程包。或者把关键部分用C/C++写成 Python 扩展，通过cytpes使Python程序直接调用C语言编译的动态库的导出函数。</p></blockquote>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GIL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>编程挺难</title>
      <link href="/2017/08/13/programming-is-hard/"/>
      <url>/2017/08/13/programming-is-hard/</url>
      <content type="html"><![CDATA[<p>今天在知乎专栏看到一篇文章《不要简单地学习编程》<a href="https://zhuanlan.zhihu.com/p/21946338" target="_blank" rel="noopener">地址</a>。</p><p><code>不要简单地学习编程。因为编程不简单。编程挺难。</code></p><p>这句话触动到了，真的挺难的。工作了毕业了一年，工作了将近2年（包括了大学期间实习）。这段时间内，感触颇深，觉得编程很难，学的东西很多很多，穷极一生也学不完。</p><p>编程总会给你带来成就感、自豪感。这个时代是个变革的时代，“编程”将会改变这个世界，促进这个时代的发展，经常为自己身处这个时代感到压力，但有种参与历史的自豪感。</p><p>我出身不好，智商也不超群，我却能从“编程”中获得快乐，放空自己，不必为琐事烦心，这便是我在“困难中挣扎”的原因。</p><p>吾将穷极一生追其一世</p>]]></content>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用Fluentd、Elasticsearch、Kibana共同组件一个实时日志分析平台</title>
      <link href="/2017/08/13/fluentd-elasticsearch-kibana/"/>
      <url>/2017/08/13/fluentd-elasticsearch-kibana/</url>
      <content type="html"><![CDATA[<ul><li><p>Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。</p></li><li><p>Fluentd是一个日志收集系统，它的特点在于其各部分均是可定制化的，你可以通过简单的配置，将日志收集到不同的地方。</p></li><li><p>Kibana也是一个开源和免费的工具，它Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。</p></li></ul><p>Fluentd的安装在博客中有提及到，在这里变不多讲了<a href="!http://hanliyi.ml/blog/share/fluentd_1.html">地址</a>。Elasticsearch与Kibana的安装详情参考<a href="!http://www.tuicool.com/articles/QFvARfr">地址</a>。</p><p>本文中主要是对Fluentd与Elasticsearch的对接进行说明，并创建Python脚本，为Python App来完成日志提交。</p><p>Fluentd配置文件<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;match project.*&gt;</span><br><span class="line">  type copy</span><br><span class="line">  &lt;store&gt;</span><br><span class="line">    type stdout</span><br><span class="line">    output_type json</span><br><span class="line">  &lt;/store&gt;</span><br><span class="line">  &lt;store&gt;</span><br><span class="line">    type elasticsearch</span><br><span class="line">    host localhost</span><br><span class="line">    port 9200</span><br><span class="line">    index_name project</span><br><span class="line">    type_name project</span><br><span class="line">    flush_interval 5s</span><br><span class="line">    logstash_format true</span><br><span class="line">    logstash_prefix project</span><br><span class="line"> &lt;/store&gt;</span><br><span class="line">&lt;/match&gt;</span><br></pre></td></tr></table></figure></p><p>我对match是<code>project.*</code>的日志分别输出到stdout和elasticsearch中。不知道为啥<code>index_name</code>与elasticsearch中的<code>_index</code>不一样。反而logstash_prefix是<code>_index</code>的前缀，并与当前日期拼接成为完整的<code>_index</code>。不知道是否和logstash_format设为true有关，但是如果没有logstash_format这个参数，elasticsearch就接收不到Fluentd的日志。</p><p>Python脚本<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> fluent <span class="keyword">import</span> handler</span><br><span class="line"></span><br><span class="line">custom_format = &#123;</span><br><span class="line">    <span class="string">'host'</span>: <span class="string">'%(hostname)s'</span>,</span><br><span class="line">    <span class="string">'where'</span>: <span class="string">'%(module)s.%(funcName)s'</span>,  <span class="comment"># 具体到文件、函数</span></span><br><span class="line">    <span class="string">'loglevel'</span>: <span class="string">'%(levelname)s'</span>,</span><br><span class="line">    <span class="string">'stack_trace'</span>: <span class="string">'%(exc_text)s'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">logging.basicConfig(level=logging.ERROR)</span><br><span class="line"></span><br><span class="line">env = os.environ.get(<span class="string">'GOOCANIMSERVICE_ENV'</span>) <span class="keyword">if</span> os.environ.get(</span><br><span class="line">    <span class="string">'GOOCANIMSERVICE_ENV'</span>) <span class="keyword">else</span> <span class="string">'local'</span></span><br><span class="line">l = logging.getLogger(<span class="string">'goocanim.'</span> + env)</span><br><span class="line"></span><br><span class="line">h = handler.FluentHandler(<span class="string">'goocanim.'</span> + env, host=<span class="string">'121.40.99.27'</span>, port=<span class="number">24224</span>)</span><br><span class="line">formatter = handler.FluentRecordFormatter(custom_format)</span><br><span class="line">h.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">l.addHandler(h)</span><br></pre></td></tr></table></figure></p><p>需要安装fluent-logger，安装命令<code>pip install fluent-logger</code>。在相应的文件中引用<code>l</code>，使用<code>l.info(...)</code>、<code>l.error(...)</code>等命令，就能将相应的日志输出到Elasticsearch中，并在Kibana中显示。</p>]]></content>
      
      
        <tags>
            
            <tag> Fluentd </tag>
            
            <tag> Elasticsearch </tag>
            
            <tag> Kibana </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>使用GEM方式安装Fluentd以及Fluentd-UI</title>
      <link href="/2017/08/13/fluentd-1/"/>
      <url>/2017/08/13/fluentd-1/</url>
      <content type="html"><![CDATA[<h5 id="Fluentd"><a href="#Fluentd" class="headerlink" title="Fluentd"></a>Fluentd</h5><p>Fluentd是一个日志收集系统，它的特点在于其各部分均是可定制化的，你可以通过简单的配置，将日志收集到不同的地方。</p><h5 id="Fluentd-UI"><a href="#Fluentd-UI" class="headerlink" title="Fluentd-UI"></a>Fluentd-UI</h5><p>FLuentd-UI提供了一个图形界面，用于对Fluentd的管理。可以对Fluentd进行启动、停止、配置等等操作</p><h5 id="Fluentd安装"><a href="#Fluentd安装" class="headerlink" title="Fluentd安装"></a>Fluentd安装</h5><p>系统：Ubuntu 14.04.5 LTS</p><p>使用了Github<a href="!https://github.com/fluent/fluentd/">地址</a>上的安装方式—-gem。</p><p>虽然安装命令简单<code>gem install fluentd</code>，但是安装得好慢、好慢、好慢。。。。</p><p>因为是使用gem安装的，所以需要Ruby。官方文档要求Ruby&gt;=1.9.3，我在机器上安装了Ruby2.3。</p><p>在<code>/etc</code>中创建<code>fluent</code>目录，在目录中运行<code>fluentd -s conf</code>初始化配置，此时会创建一个conf目录，里面是fluentd的各种配置文件。运行<code>sudo fluentd -c conf/fluent.conf</code>启动fluentd。此时在新的Bash中运行<code>echo &#39;{&quot;json&quot;:&quot;message&quot;}&#39; | fluent-cat debug.test</code>，然后在运行fluentd的Bash中将会见到<code>debug.test: {&quot;json&quot;:&quot;message&quot;}</code>出现，这样fluentd就安装好了。</p><h5 id="Fluentd-UI安装"><a href="#Fluentd-UI安装" class="headerlink" title="Fluentd-UI安装"></a>Fluentd-UI安装</h5><p>与Fluentd相同，选择gem方式安装，命令是<code>gem install -V fluentd-ui</code></p><p>因为Fluentd-UI可以对Fluentd进行管理，所以我便没有在机器上使用<code>fluentd -s conf</code>、<code>sudo fluentd -c conf/fluent.conf</code>来初始配置以及运行。</p><p>Usages:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fluentd-ui help [COMMAND]  # Describe available commands or one specific command</span><br><span class="line">fluentd-ui setup           # setup fluentd-ui server</span><br><span class="line">fluentd-ui start           # start fluentd-ui server</span><br><span class="line">fluentd-ui status          # status of fluentd-ui server</span><br><span class="line">fluentd-ui stop            # stop fluentd-ui server</span><br></pre></td></tr></table></figure></p><p>使用了Supervisor来启动Fluentd-UI。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[program:fluentd_ui]</span><br><span class="line">command=fluentd-ui start</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
        <tags>
            
            <tag> Fluentd </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker的学习（二）----构建镜像</title>
      <link href="/2017/08/13/docker-2/"/>
      <url>/2017/08/13/docker-2/</url>
      <content type="html"><![CDATA[<p>在本篇中，我将记录对Docker镜像深入的学习，已经对Dockerfile的编写和理解。</p><h6 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h6><blockquote><p>Dcoker镜像是由文件系统叠加而成的。最底端是一个引导文件系统，即bootfs。</p></blockquote><h6 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h6><p>在学习过程中，发现构建方法有两种：</p><blockquote><p>使用<code>docker commit</code>命令<br>使用<code>docker build</code>命令和Dockerfile文件</p></blockquote><ul><li><p>使用Docker的commit命令构建镜像</p><p>  类似Git中的commit，要求先创建一个容器，并在容器中进行修改，然后将修改提交创建为一个新的镜像。</p><p>  Usage:  docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</p></li><li><p>使用Dockfile构建镜像</p><p>  Dockerfile使用基本的基于DSL语法的指令来构建一个Docker镜像，之后使用<code>docker build</code>命令基于Dockerfile中的指令来构建一个新的镜像。    Dockerfile是Docker构建镜像的基础，也是Docker区别于其他容器的重要特征，正是有了Dockerfile，Docker的自动化和可移植性才成为可能。<br>  Dockerfile分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。</p></li></ul><h6 id="Dockerfile-关键字"><a href="#Dockerfile-关键字" class="headerlink" title="Dockerfile 关键字"></a>Dockerfile 关键字</h6><ul><li><strong>FROM</strong></li></ul><p>该命令定义了使用哪个基础镜像启动构建流程。基础镜像可以为任意镜像。FROM指令指定的基础image可以是官方远程仓库中的，也可以位于本地仓库。如果基础镜像没有被发现，Docker将试图从Docker image index来查找该镜像。FROM命令必须是Dockerfile的首个命令。</p><p>Usage:</p><p><code>FROM &lt;image&gt;</code></p><p><code>FROM &lt;image&gt;:&lt;tag&gt;</code></p><p><code>FROM &lt;image&gt;@&lt;digest&gt;</code></p><ul><li><strong>MAINTAINER</strong></li></ul><p>维护者信息</p><p>Usage:</p><p><code>MAINTAINER &lt;name&gt;</code></p><ul><li><strong>RUN</strong></li></ul><p>非交互式运行shell命令，RUN可以运行任何被基础image支持的命令，可以有多条。</p><p>RUN指令会在一个新的容器中执行任何命令，然后把执行后的改变提交到当前镜像，提交后的镜像会被用于Dockerfile中定义的下一步操作，RUN中定义的命令会按顺序执行并提交。当命令较长时可以使用<code>\</code>来换行。</p><p>Usage:</p><p><code>RUN &lt;command&gt; (the command is run in a shell)</code></p><p><code>RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot; ... ]  (exec form)</code></p><ul><li><strong>CMD</strong></li></ul><p>Container启动时执行的命令，但是一个Dockerfile中只能有一条CMD命令，多条则只执行最后一条CMD.</p><p>CMD主要用于Container时启动指定的服务，当<code>Docker run command</code>的命令匹配到CMD command时，会替换CMD执行的命令。</p><p>Usage:</p><p><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)</code></p><p><code>CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)</code></p><p><code>CMD command param1 param2 (shell form)</code></p><ul><li><strong>ENTRYPOINT</strong></li></ul><p>Container启动时执行的命令，但是一个Dockerfile中只能有一条ENTRYPOINT命令，如果多条，则只执行最后一条。</p><p>ENTRYPOINT没有CMD的可替换特性。</p><p>该指令的使用分为两种情况，一种是独自使用，另一种和CMD指令配合使用。</p><p>当独自使用时，如果你还使用了CMD命令且CMD是一个完整的可执行的命令，那么CMD指令和ENTRYPOINT会互相覆盖只有最后一个CMD或者ENTRYPOINT有效。</p><p>另一种用法和CMD指令配合使用来指定ENTRYPOINT的默认参数，这时CMD指令不是一个完整的可执行命令，仅仅是参数部分；ENTRYPOINT指令只能使用JSON方式指定执行命令，而不能指定参数。</p><p>Usage:</p><p><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form, preferred)</code></p><p><code>ENTRYPOINT command param1 param2 (shell form)</code></p><ul><li><strong>ADD</strong></li></ul><p>ADD只有在build镜像的时候运行一次，后面运行Container的时候不会再重新加载了。</p><p>将外部文件拷贝到镜像里,src可以为url。</p><p>将文件<src>拷贝到container的文件系统对应的路径<dest>。</dest></src></p><p>所有拷贝到Container中的文件和文件夹权限为0755,uid和gid为0。</p><p>有下载URL和解压的功能。</p><p>如果文件是可识别的压缩格式，则docker会帮忙解压缩。</p><p>如果要ADD本地文件/远程文件，则本地文件/远程文件必须在 docker build <path></path>，指定的<path></path>目录下。</p><p>需要自动下载URL并拷贝到Container时使用</p><p>Usage:</p><p><code>ADD &lt;src&gt;... &lt;dest&gt;</code></p><p><code>ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] (this form is required for paths containing whitespace)</code></p><blockquote><p><src> 是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url;</src></p></blockquote><p><dest> 是container中的绝对路径</dest></p><ul><li><strong>COPY</strong></li></ul><p>没有下载URL和解压的功能。</p><p>不需要自动下载URL并拷贝到Container时使用。</p><p>复制本地主机的 <src> （为Dockerfile所在目录的相对路径）到容器中的 <dest>。</dest></src></p><p>当使用本地目录为源目录时，推荐使用COPY。</p><p>Usage:</p><p><code>COPY &lt;src&gt;... &lt;dest&gt;</code></p><p><code>COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] (this form is required for paths containing whitespace)</code></p><ul><li><strong>ENV</strong></li></ul><p>在Image中设置一个环境变量。</p><p>设置了后，后续的RUN命令都可以使用，container启动后，可以通过docker inspect查看这个环境变量，也可以通过在docker run –env key=value时设置或修改环境变量。</p><p>Usage:</p><p><code>ENV &lt;key&gt; &lt;value&gt;</code></p><p><code>ENV &lt;key&gt;=&lt;value&gt; ...</code></p><ul><li><strong>WORKDIR</strong></li></ul><p>切换工作目录用，可以多次切换(相当于cd命令)，对RUN,CMD,ENTRYPOINT生效</p><p>Usage:</p><p><code>WORKDIR /path/to/workdir</code></p><ul><li><strong>USER</strong></li></ul><p>设置启动容器的用户，默认是root用户。</p><p>USER指令用于设置用户或uid来运行生成的镜像和执行RUN、CMD、ENTRYPOINT。</p><p>Usage:</p><p><code>USER daemon</code></p><ul><li><strong>LABEL</strong></li></ul><p>用键值对的方式来指定image的元数据</p><p>Usage:</p><p><code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...</code></p><ul><li><strong>EXPOSE</strong></li></ul><p>container内部服务开启的端口。</p><p>指定在docker允许时指定的端口进行转发。</p><p>主机上要用还得在启动Container时，做Host-Container的端口映射</p><p>Usage:</p><p><code>EXPOSE &lt;port&gt; [&lt;port&gt;...]</code></p><ul><li><strong>VOLUME</strong></li></ul><p>Usage:</p><p>使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用。</p><p>我们知道容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。</p><p>当容器中的应用有持久化数据的需求时可以在Dockerfile中使用该指令。</p><p>创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。</p><p><code>VOLUME [&quot;/data&quot;]</code></p><ul><li><strong>ARG</strong></li></ul><p>ARG是Docker1.9 版本才新加入的指令。</p><p>ARG 定义的变量只在建立Image时有效，建立完成后变量就失效消失。</p><p>Usage:</p><p><code>ARG &lt;name&gt;[=&lt;default value&gt;]</code></p><ul><li><strong>ONBUILD</strong></li></ul><p>ONBUILD 的作用就是让指令延迟執行，延迟到下一个使用 FROM 的 Dockerfile 在建立Image时执行，只限延迟一次。</p><p>ONBUILD 的使用情景是在建立镜像时取得最新的源码 (搭配 RUN) 与限定系统框架。</p><p>Usage:</p><p><code>ONBUILD [INSTRUCTION]</code></p><h6 id="第一个Dockerfile"><a href="#第一个Dockerfile" class="headerlink" title="第一个Dockerfile"></a>第一个Dockerfile</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Base ubuntu 14.04 image</span><br><span class="line"># VERSION 0.0.1</span><br><span class="line"># Authon: Ken</span><br><span class="line"></span><br><span class="line"># 基础镜像信息</span><br><span class="line">FROM ubuntu:14.04</span><br><span class="line"></span><br><span class="line"># 维护者信息</span><br><span class="line">MAINTAINER Ken ken.han.coder@aliyun.com</span><br><span class="line"></span><br><span class="line"># 镜像操作指令</span><br><span class="line">RUN mv /etc/apt/sources.list /etc/apt/sources.list.1</span><br><span class="line"># 更新源文件</span><br><span class="line">COPY sources.list /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">RUN apt-get -y update</span><br><span class="line">RUN apt-get -y upgrade</span><br><span class="line">RUN apt-get -y install vim curl wget</span><br></pre></td></tr></table></figure><h6 id="使用docker-build"><a href="#使用docker-build" class="headerlink" title="使用docker build"></a>使用docker build</h6><p>Usage:  docker build [OPTIONS] PATH | URL | -</p><p><code>docker build -t=&quot;ken_repo/ubuntu:14.04_64_base_image&quot; .</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                   IMAGE ID            CREATED             SIZE</span><br><span class="line">ken_repo/ubuntu     14.04_64_base_image   583b4e36d909        15 seconds ago      294.1 MB</span><br><span class="line">ubuntu              16.10                 175e129b1641        2 weeks ago         100.1 MB</span><br><span class="line">ubuntu              latest                42118e3df429        2 weeks ago         124.8 MB</span><br><span class="line">ubuntu              14.04                 0ccb13bf1954        2 weeks ago         188 MB</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker的学习（一）----入门</title>
      <link href="/2017/08/13/docker-1/"/>
      <url>/2017/08/13/docker-1/</url>
      <content type="html"><![CDATA[<p>之前有大致了解学习过Docker的基础操作，后来由于生活、工作搁置了对它的学习。现在要重拾起来，从头再学习，并记录在Blog中，以便复习。</p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>每学一门新技术，都必须了解它的起源、作用。简介内容摘自网上，保存用于祥读。</p><p>docker的英文本意是码头工人，也就是搬运工，这种搬运工搬运的是集装箱（Container），集装箱里面装的可不是商品货物，而是任意类型的App，Docker把App（叫Payload）装在Container内，通过Linux Container技术的包装将App变成一种标准化的、可移植的、自管理的组件，这种组件可以在你的latop上开发、调试、运行，最终非常方便和一致地运行在production环境下。</p><p>Docker的核心底层技术是LXC（Linux Container），Docker在其上面加了薄薄的一层，添加了许多有用的功能。</p><p>Docker提供了一种可移植的配置标准化机制，允许你一致性地在不同的机器上运行同一个Container；而LXC本身可能因为不同机器的不同配置而无法方便地移植运行；</p><p>Docker以App为中心，为应用的部署做了很多优化，而LXC的帮助脚本主要是聚焦于如何机器启动地更快和耗更少的内存；</p><p>Docker为App提供了一种自动化构建机制（Dockerfile），包括打包，基础设施依赖管理和安装等等；</p><p>Docker提供了一种类似git的Container版本化的机制，允许你对你创建过的容器进行版本管理，依靠这种机制，你还可以下载别人创建的Container，甚至像git那样进行合并；</p><p>Docker Container是可重用的，依赖于版本化机制，你很容易重用别人的Container（叫Image），作为基础版本进行扩展；</p><p>Docker Container是可共享的，有点类似github一样，Docker有自己的INDEX，你可以创建自己的Docker用户并上传和下载Docker Image；</p><p>Docker提供了很多的工具链，形成了一个生态系统；这些工具的目标是自动化、个性化和集成化，包括对PAAS平台的支持等；</p><p>那么Docker有什么用呢？对于运维来说，Docker提供了一种可移植的标准化部署过程，使得规模化、自动化、异构化的部署成为可能甚至是轻松简单的事情；而对于开发者来说，Docker提供了一种开发环境的管理方法，包括映像、构建、共享等功能，而后者是本文的主题。</p><p>Docker能处理的事情包括：</p><ul><li>隔离应用依赖</li><li>创建应用镜像并进行复制</li><li>创建容易分发的即启即用的应用</li><li>允许实例简单、快速地扩展</li><li>测试应用并随后销毁它们</li></ul><p>Docker三大核心概念</p><ul><li>镜像 Image ：类似于虚拟机的快照，但更轻量。</li><li>容器 Container ：镜像的一个运行实例，可以独立运行一个或一组应用。</li><li>仓库 Repository ：集中存放镜像的地方</li></ul><h3 id="Mac-安装"><a href="#Mac-安装" class="headerlink" title="Mac 安装"></a>Mac 安装</h3><blockquote><p>系统： Mac X 10.11.6</p></blockquote><p>我参考了官方文档，<a href="https://docs.docker.com/docker-for-mac/" target="_blank" rel="noopener">地址</a></p><p>Mac安装Docker很简单，只要下载安装包Docker.dmg，就行了。</p><h3 id="Linux-安装"><a href="#Linux-安装" class="headerlink" title="Linux 安装"></a>Linux 安装</h3><blockquote><p>系统：CentOS 6.8 64位</p></blockquote><p>由于VPS系统内核为2.6，不满足运行Docker的要求，需要先进行内核升级。</p><p>内核升级参考<a href="https://segmentfault.com/a/1190000000733628" target="_blank" rel="noopener">地址</a></p><p>然后就sad了，我目前用的是搬瓦工的VPS，它是OpenVZ，内核没法升级，这怎么搞，这没法搞啊。</p><p>不过之前有在Ubuntu上安装过，具体还是参考<a href="https://docs.docker.com/engine/installation/linux/ubuntulinux/" target="_blank" rel="noopener">官方文档</a></p><h3 id="使用过程"><a href="#使用过程" class="headerlink" title="使用过程"></a>使用过程</h3><p>为了解决国内使用官方Docker Hub时遇到的稳定性及速度问题，我使用了DaoCloud提供的加速器服务。详细配置过程见<a href="https://www.daocloud.io/mirror.html#accelerator-doc" target="_blank" rel="noopener">官方文档</a></p><p>官方Docker Hub 其实就是个Registry，但是它是公有的。它提供存储镜像数据，并且提供拉取和上传镜像的功能。</p><ul><li><p>镜像</p><ul><li><p>获取镜像</p><p>  Usage:  docker pull [OPTIONS] NAME[:TAG|@DIGEST]</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull ubuntu:16.10</span><br></pre></td></tr></table></figure><p>  命令分析：</p><p>  ubuntu为镜像名称，’16.10’为Tag</p></li><li><p>删除镜像</p><p>  Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER…]</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rm 42118e3df429</span><br></pre></td></tr></table></figure></li><li><p>获取镜像列表</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">→ docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">ubuntu              16.10               175e129b1641        2 weeks ago         100.1 MB</span><br><span class="line">ubuntu              latest              42118e3df429        2 weeks ago         124.8 MB</span><br></pre></td></tr></table></figure><p>上面中ubuntu并不是镜像名称，而是代表了一个名为ubuntu的Repository，同时在这个Repository下面有一系列打了Tag的Image，IMAGE ID 是一个GUID，为了方便也可以通过Repository:tag来引用。IMAGE ID相同说明Tag指向了同一个镜像文件。</p><ul><li><p>容器</p><ul><li><p>运行第一个容器</p><p>  使用 <figure class="highlight docker"><figcaption><span>run ```命令</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Usage:  docker <span class="keyword">run</span> [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure></p><p>  docker run –name first_container -it ubuntu /bin/bash</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    命令分析：</span><br><span class="line"></span><br><span class="line">    &gt;--name string      Assign a name to the container</span><br><span class="line">    -i, --interactive    Keep STDIN open even if not attached    </span><br><span class="line">    -t, --tty        Allocate a pseudo-TTY</span><br><span class="line"></span><br><span class="line">    --name的作用是为容器分配一个名称，可以用容器的名称来替代容器ID。容器名称有助于分辨容器，当构建容器和应用程序之间的逻辑连接时，容器的名称也有助于从逻辑上理解连接关系。</span><br><span class="line"></span><br><span class="line">    -i的作用是保证容器中得STDIN（标准输入）是开启的，甚至并没有附着在容器上，从而保证了持久的标准输入。</span><br><span class="line"></span><br><span class="line">    -t的作用是让Docker为被创建的容器分配一个伪tty，这样新建的容器才能提供一个交互式shell。</span><br><span class="line"></span><br><span class="line">    /bin/bash 是告诉Docker要在容器中运行/bin/bash命令，从而启动一个Bash Shell。</span><br><span class="line"></span><br><span class="line">    在网上教材中会有使用 ```ip a``` 或者 ```ifconfig``` 来检查容器的网络接口，但是在我的容器中 ``` bash: ifconfig: command not found ``` 。其实是由于设计哲学就是不推荐里面设IP，所以系统中就没有安装。</span><br><span class="line"></span><br><span class="line">    输入命令 ```exit``` 就可以退出容器返回到宿主机上。此时容器已经停止，因为只有在指定的/bin/bash命令处于运行状态的时候，我们容器也才会相应地处于运行状态。一旦退出容器，/bin/bash命令也就结束了，这时容器也随之停止了运行。</span><br><span class="line"></span><br><span class="line">* 获取容器列表</span><br><span class="line"></span><br><span class="line">    Usage:  docker ps [OPTIONS]</span><br><span class="line"></span><br><span class="line">    * 获取当前正在运行的容器列表</span><br></pre></td></tr></table></figure><pre><code>docker ps<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* 获取当前系统所有的容器列表</span><br></pre></td></tr></table></figure>docker ps -a</code></pre>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">* 容器的启动与停止</span><br><span class="line"></span><br><span class="line">    &gt;start     Start one or more stopped containers</span><br><span class="line">    stop      Stop one or more running containers</span><br><span class="line"></span><br><span class="line">    ``` docker start CONTAINER_NAME/CONTAINER_ID ``` 根据容器名称/容器ID来启动容器</span><br><span class="line"></span><br><span class="line">    ``` docker stop CONTAINER_NAME/CONTAINER_ID ``` 根据容器名称/容器ID来停止容器</span><br><span class="line"></span><br><span class="line">* attach</span><br><span class="line"></span><br><span class="line">     &gt;attach   Attach to a running container</span><br><span class="line"></span><br><span class="line">    Usage:  docker attach [OPTIONS] CONTAINER</span><br><span class="line"></span><br><span class="line">     ```docker attach 0406e38d7fea``` 可以附着到一个容器ID为0406e38d7fea的并且正在运行的容器。</span><br><span class="line"></span><br><span class="line">* exec</span><br><span class="line"></span><br><span class="line">    &gt; exec      Run a command in a running container</span><br><span class="line"></span><br><span class="line">    Usage:  docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br><span class="line"></span><br><span class="line">    通过docker exec命令在容器内部额外启动新进程。可以在容器内运行的进程有两种类型：后台任务和交互式任务。后台任务在容器内运行且没有交互需求，而交互式任务则保持在前台运行。对于需要在容器内部打开shell的任务，交互式任务是很实用的。</span><br><span class="line"></span><br><span class="line">    * 后台任务</span><br><span class="line"></span><br><span class="line">        &gt;-d, --detach   Detached mode: run command in the background</span><br><span class="line"></span><br><span class="line">        ```docker exec -d 0406e38d7fea touch ~/test</span><br></pre></td></tr></table></figure><pre><code>命令分析：-d的作用是开启后台模式，将命令行命令运行在后台。该命令的作用是在&apos;~/&apos;目录下创建了个test文件</code></pre><ul><li><p>交互式任务</p><blockquote><p>-i, –interactive    Keep STDIN open even if not attached<br>  -t, –tty            Allocate a pseudo-TTY</p></blockquote><p>  docker exec -it 0406e38d7fea /bin/bash</p></li></ul></li><li><p>容器的删除</p><p>  Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER…]</p>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker rm 0406e38d7fea</span><br></pre></td></tr></table></figure><blockquote><p>运行中的Docker容器是无法删除的</p></blockquote></li></ul></li></ul>]]></content>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker的学习（三）----使用Dockerfile部署一个Flask项目</title>
      <link href="/2017/08/13/dcoker-3/"/>
      <url>/2017/08/13/dcoker-3/</url>
      <content type="html"><![CDATA[<p>建立了一个基础Ubuntu镜像、Nginx镜像及Python镜像。</p><p>使用了docker-compose提供堆栈完成多容器的组装，完成部署一个Flask项目。</p><p>项目的Github地址：<a href="https://github.com/kenhancoder/docker_repo" target="_blank" rel="noopener">https://github.com/kenhancoder/docker_repo</a></p><h5 id="基础Ubuntu镜像"><a href="#基础Ubuntu镜像" class="headerlink" title="基础Ubuntu镜像"></a>基础Ubuntu镜像</h5><p>创建了基础镜像repo/ubuntu:16.04_64_Base，镜像基于phusion/baseimage:0.9.19 <a href="!https://github.com/phusion/baseimage-docker">Github地址</a></p><p>Dockerfile如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基础镜像信息</span><br><span class="line">FROM phusion/baseimage:0.9.19</span><br><span class="line"></span><br><span class="line"># Use baseimage-docker&apos;s init system.</span><br><span class="line">CMD [&quot;/sbin/my_init&quot;]</span><br><span class="line"></span><br><span class="line"># ...put your own build instructions here...</span><br><span class="line"></span><br><span class="line"># 时区</span><br><span class="line">RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line"># 清华大学源</span><br><span class="line">RUN mv /etc/apt/sources.list /etc/apt/sources.list.1</span><br><span class="line">COPY sources.list /etc/apt/sources.list</span><br><span class="line"></span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN DEBIAN_FRONTEND=noninteractive apt-get install -y \</span><br><span class="line">                vim \</span><br><span class="line">                curl \</span><br><span class="line">                wget \</span><br><span class="line">                build-essential \</span><br><span class="line">                python-software-properties \</span><br><span class="line">                python-dev \</span><br><span class="line">                python-pip \</span><br><span class="line">                supervisor</span><br><span class="line"></span><br><span class="line">RUN mkdir /etc/service/supervisor</span><br><span class="line">ADD supervisor.sh /etc/service/supervisor/run</span><br><span class="line"></span><br><span class="line"># Clean up APT when done.</span><br><span class="line">RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*</span><br></pre></td></tr></table></figure></p><p>运行<code>docker build -t=&#39;repo/ubuntu:16.04_64_Base&#39; .</code></p><h5 id="Nginx镜像"><a href="#Nginx镜像" class="headerlink" title="Nginx镜像"></a>Nginx镜像</h5><p>Dockerfile如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基础镜像信息</span><br><span class="line">FROM repo/ubuntu:16.04_64_Base</span><br><span class="line"></span><br><span class="line"># 维护者信息</span><br><span class="line">MAINTAINER Ken ken.han.coder@aliyun.com</span><br><span class="line"></span><br><span class="line">RUN add-apt-repository -y ppa:nginx/stable</span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN DEBIAN_FRONTEND=noninteractive apt-get install -y nginx</span><br><span class="line"></span><br><span class="line">COPY nginx.conf /etc/nginx/conf</span><br><span class="line"></span><br><span class="line">EXPOSE 80 443</span><br><span class="line"></span><br><span class="line">CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br><span class="line"></span><br><span class="line"># Clean up APT when done.</span><br><span class="line">RUN apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*</span><br></pre></td></tr></table></figure></p><p>运行<code>docker build -t=&#39;repo/nginx:1.10.1_Base&#39; .</code></p><h5 id="Python镜像"><a href="#Python镜像" class="headerlink" title="Python镜像"></a>Python镜像</h5><p>Dockerfile如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基础镜像信息</span><br><span class="line">FROM repo/ubuntu:16.04_64_Base</span><br><span class="line"></span><br><span class="line"># 维护者信息</span><br><span class="line">MAINTAINER Ken ken.han.coder@aliyun.com</span><br><span class="line"></span><br><span class="line"># 镜像操作指令</span><br><span class="line">COPY ./conf/pip.conf /root/.pip/pip.conf </span><br><span class="line">ADD requirements.txt requirements.txt</span><br><span class="line"></span><br><span class="line">RUN pip install --upgrade pip</span><br><span class="line">RUN pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">RUN mkdir -p /var/www</span><br><span class="line">COPY app.py /var/www/app.py</span><br><span class="line"></span><br><span class="line">WORKDIR /var/www</span><br><span class="line"></span><br><span class="line">EXPOSE 8765</span><br></pre></td></tr></table></figure></p><p>Flask代码如下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line">from flask import Flask</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">def hello_world():</span><br><span class="line">    return &apos;Hello World!&apos;</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run(host=&quot;0.0.0.0&quot;, port=8765)</span><br></pre></td></tr></table></figure></p><p>运行<code>docker build -t=&quot;repo/flask_demo:0.1&quot; .</code></p><blockquote><p>host一定不要用默认的”127.0.0.1”，不然容器启动，即使映射了端口，在浏览器中也仍然是无法访问服务的。<br>将host设置为”0.0.0.0”，这样Flask容器可以接受到宿主的请求。</p></blockquote><p>nginx配置文件如下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen  8765;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_set_header Access-Control-Allow-Origin *;</span><br><span class="line">        proxy_pass_header Server;</span><br><span class="line">        proxy_set_header Host $http_host;</span><br><span class="line">        proxy_redirect off;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Scheme $scheme;</span><br><span class="line">        proxy_pass http://web:8765;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>proxy_pass中的’web’为docker-compose.yml中的links的web</p></blockquote><p>#####Docker Compose<br>使用Docker Compose，可以用一个YAML文件定义一组要启动的容器，以及容器运行时的属性。Docker Compose称这些容器为“服务”，像这样定义：<code>容器通过某些方法并指定一些运行时的属性来和其他容器产生交互</code>。</p><p>可以在一个文件中定义一个多容器的应用，然后使用一条命令来启动你的应用，然后所有相关的操作都会被自动完成</p><p>docker-compose.yml如下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server:</span><br><span class="line">  restart: always</span><br><span class="line">  image: repo/nginx:1.10.1_Base</span><br><span class="line">  volumes:</span><br><span class="line">    - ./conf/nginx_flask_demo.conf:/etc/nginx/conf.d/flask_demo.conf</span><br><span class="line">  links:</span><br><span class="line">    - web</span><br><span class="line">  ports:</span><br><span class="line">    - &quot;8765:8765&quot;</span><br><span class="line"></span><br><span class="line">web:</span><br><span class="line">  restart: always</span><br><span class="line">  image: repo/flask_demo:0.1</span><br><span class="line">  working_dir: /var/www</span><br><span class="line">  expose:</span><br><span class="line">    - &quot;8765&quot;</span><br><span class="line">  command: python /var/www/app.py</span><br></pre></td></tr></table></figure><blockquote><p>可以将command中的启动命令换成gunicorn来启动。</p></blockquote><h5 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h5><p>在docker-compose.yml的同级目录下运行<code>docker-compose up -d</code></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><h6 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h6><ul><li><p>RUN和CMD都是执行命令，他们的差异在于RUN中定义的命令会在执行docker build命令创建镜像时执行，而CMD中定义的命令会在执行docker run命令运行镜像时执行，另外使用第一种语法也就是调用exec执行时，命令必须为绝对路径。</p></li><li><p>使用<code>Docker build</code>命令时，可以使用<code>-f</code>参数来选择指定的Dockerfile。如<code>docker build -t=&quot;repo/server_flask:local_0.1&quot; -f=&quot;Dockerfile_local&quot; .</code></p></li></ul><h6 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h6><ul><li><p>我在YAML文件大多使用已经创建好的镜像，即使用<code>image</code>参数。Docker Compose也提供参数<code>build</code>，参数值为Dockerfile的目录路径，所以只能将Dockerfile文件命名为”Dockerfile”，缺少灵活性。</p></li><li><p>使用<code>-f</code>参数可以选择指定docker-compose.yml，例如<code>docker-compose -f docker-compose-local.yml up -d</code>，这将根据docker-compose-local.yml来启动容器。</p></li></ul>]]></content>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Ubuntu中为Apache使用uWsgi</title>
      <link href="/2017/08/13/apache-use-uwsgi/"/>
      <url>/2017/08/13/apache-use-uwsgi/</url>
      <content type="html"><![CDATA[<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libapache2-mod-uwsgi</span><br></pre></td></tr></table></figure><h3 id="启动module"><a href="#启动module" class="headerlink" title="启动module"></a>启动module</h3><p>module具体名称需要进入/etc/apache2/mods-available/确认。在我的机子上为uwsgi.load<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo a2enmod uwsgi</span><br></pre></td></tr></table></figure></p><h3 id="Apache配置"><a href="#Apache配置" class="headerlink" title="Apache配置"></a>Apache配置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;VirtualHost *:8001&gt;</span><br><span class="line">    &lt;Location /&gt;</span><br><span class="line">        SetHandler uwsgi-handler</span><br><span class="line">        uWSGISocket 127.0.0.1:7001</span><br><span class="line">    &lt;/Location&gt;</span><br><span class="line">&lt;/VirtualHost&gt;</span><br></pre></td></tr></table></figure><blockquote><ul><li>8001：Apache监听端口</li><li>uWSGISocket：uWsgi启动时所使用的地址与端口</li></ul></blockquote>]]></content>
      
      
        <tags>
            
            <tag> Apache </tag>
            
            <tag> uWsgi </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
